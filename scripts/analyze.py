import os
import pandas as pd
import numpy as np
import pickle
import csv
from utils import *

def read_pickle_file(file_path):
    with open(file_path, 'rb') as file:
        data = pickle.load(file)
    return data

def read_csv_file(file_path):
    with open(file_path, 'r') as file:
        reader = csv.reader(file)
        data = list(reader)
    return data

def generate_schemas(generation_fitnesses):
    schemas = []
    for generation in generation_fitnesses:
        for solution in generation:
            # Generate schema from solution
            schema = generate_schema(solution)
            schemas.append(schema)
    return schemas

def generate_schema(solution):
    # Generate schema from solution
    pass

def stats_generation_schema_fitnesses(generation_schemata_fitnesses):
    """Return stats on the schema fitnesses for each generation.

    Min fitness, max fitness, avg fitness, median fitness, std dev fitness
    by schema group (e.g. 000*, 0*0*, 0**0, etc.)

    Args:
        generation_schemata_fitnesses (_type_): _description_
    """
    if not generation_schemata_fitnesses:
        return {}

    simulation_stats = {}
    # For each generation, calculate the min, max, avg, median, std dev fitness for each schema group
    for generation, state in enumerate(generation_schemata_fitnesses.values()):
        generation_min_fitnesses = []
        generation_max_fitnesses = []
        generation_median_fitnesses = []
        generation_stats = {}
        generation_schemata = generation_schemata_fitnesses[generation].keys()
    # list of average fitnesses across all schema groups in this generation
        fitnesses = [state[schema]["avg_fitness"] for schema in generation_schemata]
        # TODO: implement this for each generation to create the list of average fitnesses for each schema group
        # This is input to exploratory stats like min, max, median, std dev
        # [generation_schemata_fitnesses[99][schema]["avg_fitness"] for schema in [generation_schemata_fitnesses[g] for g in generation_schemata_fitnesses][99]]
        generation_min_fitnesses.append(np.min(fitnesses))
        generation_max_fitnesses.append(np.max(fitnesses))
        generation_median_fitnesses.append(np.median(fitnesses))

        generation_stats =  {
            'min_fitness': generation_min_fitnesses,
            'max_fitness': generation_max_fitnesses,
            # 'avg_fitness': avg_fitnesses,
            'median_fitness': generation_median_fitnesses,
            # 'std_dev_fitness': std_dev_fitnesses
        }
        simulation_stats[generation] = generation_stats
    return simulation_stats

if __name__ == '__main__':
    # Read in data
    fname = "b9e39d66-c61e-4576-9a46-8833969b59c9"
    states = read_pickle_file("./data/" + fname + ".pickle")
    # schemas = generate_schemas(generation_fitnesses)
    schemata_fitnesses = {}
    generation_schemata_fitnesses = {}
    # each schema is a key, with a second dictionary with keys: "avg_fitness", "count"
    # { "000*": {"avg_fitness": 0.2, "count": 5}, "0*0*": {"avg_fitness": 0.4, "count": 2}, "0**0": {"avg_fitness": 0.7, "count": 5} }
    # generate_population_from_schemata("000*0*10000*0*1")

    # Initialize a list to store the solution schemata for this generation
    records = []
    for generation in states["data"]:
        for solution in generation["generation_fitnesses"]:
            # Generate schema from solution
            schemata = generate_schemas_from_solution(solution[0])
            # Remove the "all wildcards" schema that is generated by the recursive `generate_schemas_from_solution` function
            schemata = schemata[:-1]
            
            # columns: generation, solution, x, y, fitness, schema
            row = [
                generation["generation"],
                solution[0],
                solution[1][0],
                solution[1][1],
                solution[2],
                schemata
            ]
            records.append(row)
        print("Finished generation: \t", generation["generation"])
    print("Creating dataframe...")
    df = pd.DataFrame(records, columns=["generation", "solution", "x", "y", "fitness", "schemata"])
    final_df = df.set_index(["generation", "solution", "x", "y", "fitness"])["schemata"].apply(pd.Series).stack()
    final_df = final_df.reset_index()
    final_df.columns = ["generation", "solution", "x", "y", "fitness", "schema", "wildcard"]
    final_df = final_df.drop(columns=["schema"])

    # Create a dataframe of the schema fitnesses for each generation
    # df = pd.DataFrame(records, columns=["generation", "solution", "x", "y", "fitness", "schemata"]).set_index('generation')

    # Stack the dataframe so that each row is a schema for a given generation


            # # Add schema to dictionary if it doesn't exist
            # schemata_fitnesses[generation["generation"]] = schemata
            # if schema not in schemata_fitnesses.keys():
            #     schemata_fitnesses[schema] = {"sum_fitness": solution[2], "avg_fitness": solution[2], "count": 1}
            # else:
            #     pass
        # schemata_fitnesses[generation["generation"]] = schemata_population
        
        # records = []
        # row = [

        # ]
        # for generation, data in schemata_fitnesses.items():
        #     for solution in data:
        #         for schema in solution[3]:
        #             record = {
        #                 'generation': generation,
        #                 'solution': solution[0],
        #                 'x': solution[1][0],
        #                 'y': solution[1][1],
        #                 'fitness': solution[2],
        #                 'schema': schema
        #             }
        #             records.append(record)

        # df = pd.DataFrame(records).set_index('generation')  
        # schemata = generate_schemas_from_population(generation["population"])
        # counts = count_schemata(schemata, {})
        # print(counts)
        # Initialize a dictionary to store the average fitness of each schema this generation
    #     schemata_fitnesses = {}
    #     # Calculate average schema fitness by solution
    #     ls = [length(s) for s in schemata]
    #     for solution in generation["generation_fitnesses"]:
    #         solution_schemata = generate_schemas_from_solution(solution[0]) 
    #         # Remove the "all wildcards" schema that is generated by the recursive `generate_schemas_from_solution` function
    #         solution_schemata = solution_schemata[:-1]
    #         for schema in solution_schemata:
    #             if schema in schemata_fitnesses.keys():
    #                 schemata_fitnesses[schema]["sum_fitness"] += solution[2]
    #                 schemata_fitnesses[schema]["count"] += 1
    #                 schemata_fitnesses[schema]["avg_fitness"] = schemata_fitnesses[schema]["sum_fitness"] / schemata_fitnesses[schema]["count"]
    #             else: # initialize this new schema
    #                 schemata_fitnesses[schema] = {"sum_fitness": solution[2], "avg_fitness": solution[2], "count": 1}
    #     generation_schemata_fitnesses[generation["generation"]] = schemata_fitnesses
    #     # print(generation_schemata_fitnesses)
    # stats = stats_generation_schema_fitnesses(generation_schemata_fitnesses)
    # print(stats)

    # Create dataframe of schemata and fitnesses for each generation
    # df = pd.DataFrame.from_dict({(i,j): generation_schemata_fitnesses[i][j] 
    #                        for i in generation_schemata_fitnesses.keys() 
    #                        for j in generation_schemata_fitnesses[i].keys()},
    #                    orient='index')
    # df.index.names = ['generation', 'schema']
    # # Write data to file
    print("Writing data to file...")
    print("Filename: ", fname + ".pickle")
    output_fname = "./data/objective/six-hump-camelback/schemata/" + fname + ".pickle"
    
    dir_name = os.path.dirname(output_fname)

    if not os.path.exists(dir_name):
        os.makedirs(dir_name)

    with open(output_fname, 'wb') as f:
        pickle.dump(final_df, f)

# TODO:
# Visualize all the points in the fitness landscape by schemata (using the underlying solutions that belong to that schema group)
